{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek.sawalkar/opt/anaconda3/envs/ml3/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/abhishek.sawalkar/opt/anaconda3/envs/ml3/lib/python3.6/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  \"Using `json`-module for json-handling. \"\n"
     ]
    }
   ],
   "source": [
    "from pts.model.tempflow import TempFlowEstimator\n",
    "from pts.model.time_grad import TimeGradEstimator\n",
    "from pts.model.transformer_tempflow import TransformerTempFlowEstimator\n",
    "from pts import Trainer\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.repository.datasets import dataset_recipes, get_dataset\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../dataset/AirQualityUCI_Italy.csv\",sep=\";\",parse_dates={ 'DateTime': ['Date','Time']},index_col='DateTime',usecols=[0,1,3])\n",
    "df.dropna(inplace=True)\n",
    "df.index=pd.to_datetime(df.index, format='%d/%m/%Y %H.%M.%S')\n",
    "# df.rename(columns = {'PT08.S1(CO)':np.int64(0)}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7485\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train, test = train_test_split(df, test_size=0.2)\n",
    "train_size=(len(df)*8)//10\n",
    "print(train_size)\n",
    "train, test = df.iloc[:train_size],df.iloc[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for describing dataframe\n",
    "def desc_df(df):\n",
    "    print(\"\\nType:\",type(df))\n",
    "    print(\"\\nShape:\",df.shape)\n",
    "    print(\"\\nDatatypes:\",df.dtypes)\n",
    "    print(\"\\nDescription:\",df.describe())\n",
    "    print(\"\\nHead:\",df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Shape: (7485, 1)\n",
      "\n",
      "Datatypes: PT08.S1(CO)    float64\n",
      "dtype: object\n",
      "\n",
      "Description:        PT08.S1(CO)\n",
      "count  7485.000000\n",
      "mean   1052.568604\n",
      "std     327.724860\n",
      "min    -200.000000\n",
      "25%     922.000000\n",
      "50%    1055.000000\n",
      "75%    1228.000000\n",
      "max    2040.000000\n",
      "\n",
      "Head:                      PT08.S1(CO)\n",
      "DateTime                        \n",
      "2004-03-10 18:00:00       1360.0\n",
      "2004-03-10 19:00:00       1292.0\n",
      "2004-03-10 20:00:00       1402.0\n",
      "2004-03-10 21:00:00       1376.0\n",
      "2004-03-10 22:00:00       1272.0\n",
      "2004-03-10 23:00:00       1197.0\n",
      "2004-03-11 00:00:00       1185.0\n",
      "2004-03-11 01:00:00       1136.0\n",
      "2004-03-11 02:00:00       1094.0\n",
      "2004-03-11 03:00:00       1010.0\n"
     ]
    }
   ],
   "source": [
    "desc_df(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7485,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"PT08.S1(CO)\"][:7485].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "train_data=ListDataset(\n",
    "    [\n",
    "        {\"start\":df.index[0],\"target\":df[\"PT08.S1(CO)\"][:7485]}\n",
    "        # {\"start\":df.index[0],\"target\":train}\n",
    "        # {\"start\":df.index[0],\"target\":df.iloc[0:7485,1:3],}\n",
    "        # {\n",
    "        #     FieldName.START:train.index[0],\n",
    "        #     FieldName.TARGET:train\n",
    "        # }\n",
    "    ],\n",
    "    freq = \"1H\"\n",
    "    # ,one_dim_target=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "grouper_train = MultivariateGrouper()\n",
    "\n",
    "train_data = grouper_train(train_data)\n",
    "# train_data=list(train_data)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gluonts.dataset.common.ListDataset"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for TimeGradTrainingNetworkModel\ntarget_dim\n  value is not a valid integer (type=type_error.integer)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-94447e3ac650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                     batch_size=2,)\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#         except RuntimeError:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#             continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishek.sawalkar/opt/anaconda3/envs/ml3/lib/python3.6/site-packages/pts/model/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, validation_data, num_workers, prefetch_factor, shuffle_buffer_length, cache_data, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mshuffle_buffer_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_buffer_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mcache_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         ).predictor\n",
      "\u001b[0;32m/Users/abhishek.sawalkar/opt/anaconda3/envs/ml3/lib/python3.6/site-packages/pts/model/estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_data, validation_data, num_workers, prefetch_factor, shuffle_buffer_length, cache_data, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mtransformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtrained_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_module_forward_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishek.sawalkar/opt/anaconda3/envs/ml3/lib/python3.6/site-packages/pts/model/time_grad/time_grad_estimator.py\u001b[0m in \u001b[0;36mcreate_training_network\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mlags_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlags_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mconditioning_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditioning_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         ).to(device)\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishek.sawalkar/opt/anaconda3/envs/ml3/lib/python3.6/site-packages/gluonts/core/component.py\u001b[0m in \u001b[0;36minit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"self\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             }\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPydanticModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnmargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# merge nmargs, kwargs, and the model fields into a single dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abhishek.sawalkar/opt/anaconda3/envs/ml3/lib/python3.6/site-packages/pydantic/main.cpython-36m-darwin.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for TimeGradTrainingNetworkModel\ntarget_dim\n  value is not a valid integer (type=type_error.integer)"
     ]
    }
   ],
   "source": [
    "# def run():\n",
    "#     for i in range(1500,10000):\n",
    "#         try:\n",
    "\n",
    "estimator = TimeGradEstimator(\n",
    "    target_dim=[1],\n",
    "    # target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=1872,\n",
    "    context_length=1872,\n",
    "    cell_type='GRU',\n",
    "    input_size=28,\n",
    "    freq=\"1H\",\n",
    "    loss_type='l2',\n",
    "    scaling=True,\n",
    "    diff_steps=100,\n",
    "    beta_end=0.1,\n",
    "    beta_schedule=\"linear\",\n",
    "    trainer=Trainer(device=device,\n",
    "                    epochs=20,\n",
    "                    learning_rate=1e-3,\n",
    "                    num_batches_per_epoch=100,\n",
    "                    batch_size=2,)\n",
    ")\n",
    "predictor = estimator.train(train_data)\n",
    "#         except RuntimeError:\n",
    "#             continue\n",
    "#             # print(i)\n",
    "#         except Exception as e:\n",
    "#             print(i,e)\n",
    "#             break\n",
    "# run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
